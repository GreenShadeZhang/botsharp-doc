<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>LLM Provider | botsharp-doc</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="LLM Provider" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Provide documentation for using botsharp in multiple languages" />
<meta property="og:description" content="Provide documentation for using botsharp in multiple languages" />
<link rel="canonical" href="https://greenshadezhang.github.io/botsharp-doc/en/guide/llm/provider.html" />
<meta property="og:url" content="https://greenshadezhang.github.io/botsharp-doc/en/guide/llm/provider.html" />
<meta property="og:site_name" content="botsharp-doc" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="LLM Provider" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","description":"Provide documentation for using botsharp in multiple languages","headline":"LLM Provider","url":"https://greenshadezhang.github.io/botsharp-doc/en/guide/llm/provider.html"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="stylesheet" href="/botsharp-doc/assets/css/style.css?v=3d2618142f9f02b2b8291054823fd3111a5f052b">
    <!-- start custom head snippets, customize with your own _includes/head-custom.html file -->

<!-- Setup Google Analytics -->



<!-- You can set your favicon here -->
<!-- link rel="shortcut icon" type="image/x-icon" href="/botsharp-doc/favicon.ico" -->

<!-- end custom head snippets -->

  </head>
  <body>
    <div class="container-lg px-3 my-5 markdown-body">
      
      <h1><a href="https://greenshadezhang.github.io/botsharp-doc/">botsharp-doc</a></h1>
      

      <h1 id="llm-provider">LLM Provider</h1>

<p><code class="language-plaintext highlighter-rouge">BotSharp</code> can support multiple LLM providers through plug-ins, one <code class="language-plaintext highlighter-rouge">provider</code> could contain several <code class="language-plaintext highlighter-rouge">model</code> settings.</p>
<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">[{</span><span class="w">
  </span><span class="nl">"Provider"</span><span class="p">:</span><span class="w"> </span><span class="s2">"azure-openai"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"Models"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
    </span><span class="p">{</span><span class="w">
      </span><span class="nl">"Id"</span><span class="p">:</span><span class="w"> </span><span class="s2">""</span><span class="p">,</span><span class="w">
      </span><span class="nl">"Name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"gpt-35-turbo"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"Group"</span><span class="p">:</span><span class="w"> </span><span class="s2">""</span><span class="p">,</span><span class="w">
      </span><span class="nl">"ApiKey"</span><span class="p">:</span><span class="w"> </span><span class="s2">""</span><span class="p">,</span><span class="w">
      </span><span class="nl">"Endpoint"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://gpt-35-turbo.openai.azure.com/"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"Type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"chat"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"PromptCost"</span><span class="p">:</span><span class="w"> </span><span class="mf">0.0015</span><span class="p">,</span><span class="w">
      </span><span class="nl">"CompletionCost"</span><span class="p">:</span><span class="w"> </span><span class="mf">0.002</span><span class="w">
    </span><span class="p">},</span><span class="w">
    </span><span class="p">{</span><span class="w">
      </span><span class="nl">"Name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"gpt-35-turbo-instruct"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"ApiKey"</span><span class="p">:</span><span class="w"> </span><span class="s2">""</span><span class="p">,</span><span class="w">
      </span><span class="nl">"Endpoint"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://gpt-35-turbo-instruct.openai.azure.com/"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"Type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"text"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"PromptCost"</span><span class="p">:</span><span class="w"> </span><span class="mf">0.0015</span><span class="p">,</span><span class="w">
      </span><span class="nl">"CompletionCost"</span><span class="p">:</span><span class="w"> </span><span class="mf">0.002</span><span class="w">
    </span><span class="p">}</span><span class="w">
  </span><span class="p">]</span><span class="w">
</span><span class="p">}]</span><span class="w">
</span></code></pre></div></div>

<p>You can set the names of <code class="language-plaintext highlighter-rouge">Provider</code> and <code class="language-plaintext highlighter-rouge">Model</code> in each round of dialogue to control the LLM that should be used in the current dialogue, or you can also specify the LLM used in subsequent dialogues once during dialogue initialization.</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"text"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Good morning!"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"provider"</span><span class="p">:</span><span class="w"> </span><span class="s2">"google-ai"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"model"</span><span class="p">:</span><span class="w"> </span><span class="s2">"palm2"</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<h2 id="load-balancing">Load balancing</h2>

<p>If you have deployed models with the same functions in multiple regions and want to establish a load balance among these regions to reduce the resource constraints of large model providers, you need to set a consistent Group value in the model configuration.</p>


      
      <div class="footer border-top border-gray-light mt-5 pt-3 text-right text-gray">
        This site is open source. <a href="https://github.com/GreenShadeZhang/botsharp-doc/edit/gh-pages/en/guide/llm/provider.md">Improve this page</a>.
      </div>
      
    </div>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.1.0/anchor.min.js" integrity="sha256-lZaRhKri35AyJSypXXs4o6OPFTbTmUoltBbDCbdzegg=" crossorigin="anonymous"></script>
    <script>anchors.add();</script>
  </body>
</html>
